{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_using_gpu.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPV9VruK5YhFiZuAQKU5Rel"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYcyjCHxXDm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOS3fLmG7peC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsZC_LlHNlW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1tz-hgjNqec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5JRcqW97FET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.metrics import auc, roc_curve\n",
        "from sklearn.neighbors import KernelDensity\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "# from absl import app, flags, logging\n",
        "# from data import DataCIFAR10, DataGTSRB\n",
        "# from model import Model, ModelSAP, SimpleModel\n",
        "\n",
        "torch.manual_seed(23)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP-mlPxFOPva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import logging\n",
        "logger = logging.getLogger()\n",
        "handler = logging.StreamHandler(sys.stdout)\n",
        "handler.setLevel(logging.INFO)\n",
        "logger.addHandler(handler)\n",
        "logger.setLevel(logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO1XTRK3NSFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flags():\n",
        "    log_dir = \"\"\n",
        "    dataset = \"cifar10\"  # ['cifar10', 'GTSRB_processed']\n",
        "    is_train = True\n",
        "    model = \"normal\"  # ['simple', 'normal', 'normalSAP']\n",
        "    train_method = \"none\"  # ['none', 'fgsm', 'rfgsm', 'ifgsm', 'mifgsm']\n",
        "    epochs = 150\n",
        "    batch_size = 32\n",
        "    epsilon = 4. / 255\n",
        "    alpha = 2. / 255\n",
        "    step = 20\n",
        "    use_atda_loss = False\n",
        "    is_test = True\n",
        "    model_name_for_test = None\n",
        "    test_method = \"fgsm\"  # ['none', 'fgsm', 'rfgsm', 'ifgsm', 'mifgsm']\n",
        "    is_kde_test = False\n",
        "    is_random_crop_test = False\n",
        "\n",
        "FLAGS = Flags()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h7EOLSnbgM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as _F\n",
        "\n",
        "\n",
        "class Data(ABC):\n",
        "    \"\"\"Data represents an abstract class providing interfaces.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    base_dit str : base directory of data.\n",
        "    self.batch_size int : batch size.\n",
        "    self.num_workers int : number of workers used in multi-process data loding.\n",
        "    \"\"\"\n",
        "    base_dir = \"./data\"\n",
        "\n",
        "    def __init__(self, batch_size, num_workers):\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "    @abstractmethod\n",
        "    def transform(self) -> torchvision.transforms.transforms.Compose:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_dataset(self) -> torchvision.datasets.vision.VisionDataset:\n",
        "        pass\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"Get and return dataset with transformations.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        trainloader torch.utils.data.DataLoader : train DataLoader.\n",
        "        testloader torch.utils.data.DataLoader :  test DataLoader.\n",
        "        num_classes int : number of classes of dataset.\n",
        "        \"\"\"\n",
        "        trainset, testset = self.get_dataset()\n",
        "        num_classes = len(trainset.classes)\n",
        "\n",
        "        trainloader = torch.utils.data.DataLoader(trainset,\n",
        "                                                  batch_size=self.batch_size,\n",
        "                                                  shuffle=True,\n",
        "                                                  num_workers=self.num_workers)\n",
        "        testloader = torch.utils.data.DataLoader(testset,\n",
        "                                                 batch_size=self.batch_size,\n",
        "                                                 shuffle=False,\n",
        "                                                 num_workers=self.num_workers)\n",
        "\n",
        "        return trainloader, testloader, num_classes\n",
        "\n",
        "\n",
        "class DataCIFAR10(Data):\n",
        "    \"\"\"DataCIFAR10 represents cifar10 dataset.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    name str : \"cifar10\".\n",
        "    \"\"\"\n",
        "    name = \"cifar10\"\n",
        "\n",
        "    def __init__(self, batch_size=4, num_workers=2):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch_size int : batch_size.\n",
        "        num_workers int : number of workers used in multi-process data loding.\n",
        "        \"\"\"\n",
        "        super(DataCIFAR10, self).__init__(batch_size, num_workers)\n",
        "\n",
        "    def transform(self):\n",
        "        \"\"\"Only uses transforms.ToTensor().\"\"\"\n",
        "        return transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    def get_dataset(self):\n",
        "        \"\"\"Download and load cifar10 dataset.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        trainset torchvision.datasets.CIFAR10 : train dataset.\n",
        "        testset torchvision.datasets.CIFAR10 : test dataset.\n",
        "        \"\"\"\n",
        "        trainset = torchvision.datasets.CIFAR10(root=f\"{self.base_dir}/{self.name}\",\n",
        "                                                train=True, download=True,\n",
        "                                                transform=self.transform())\n",
        "        testset = torchvision.datasets.CIFAR10(root=f\"{self.base_dir}/{self.name}\",\n",
        "                                               train=False, download=True,\n",
        "                                               transform=self.transform())\n",
        "\n",
        "        return trainset, testset\n",
        "\n",
        "\n",
        "class DataGTSRB(Data):\n",
        "    \"\"\"DataGTSRB represents pre-processed GTSRB dataset.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    name str : \"GTSRB_processed\".\n",
        "    \"\"\"\n",
        "    name = \"GTSRB_processed\"\n",
        "\n",
        "    def __init__(self, batch_size=4, num_workers=2):\n",
        "        super(DataGTSRB, self).__init__(batch_size, num_workers)\n",
        "\n",
        "    def transform(self):\n",
        "        \"\"\"Only uses transforms.ToTensor().\"\"\"\n",
        "        return transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    def get_dataset(self):\n",
        "        \"\"\"Load GTSRB dataset from directory that is prepared in advance.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        trainset torchvision.datasets.ImageFolder : train dataset.\n",
        "        testset torchvision.datasets.ImageFolder : test dataset.\n",
        "        \"\"\"\n",
        "        trainset = torchvision.datasets.ImageFolder(\n",
        "            root=f\"{self.base_dir}/{self.name}/train\",\n",
        "            transform=self.transform())\n",
        "\n",
        "        testset = torchvision.datasets.ImageFolder(\n",
        "            root=f\"{self.base_dir}/{self.name}/test\",\n",
        "            transform=self.transform())\n",
        "\n",
        "        return trainset, testset\n",
        "\n",
        "\n",
        "class RandomResizePadding(object):\n",
        "    \"\"\"DataGTSRB represents pre-processed GTSRB dataset.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    self.size int : image will be rescaled to [c, size, size].\n",
        "    \"\"\"\n",
        "    def __init__(self, size):\n",
        "        assert isinstance(size, int)\n",
        "        self.size = size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"Randomly resize and 0-pad the given PIL.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        img PIL.Image : input image.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        img PIL.Image : trasnsormed image.\n",
        "        \"\"\"\n",
        "        # Randomly resize the image.\n",
        "        resize = random.randint(img.width, self.size)\n",
        "        resized_img = _F.resize(img, resize)\n",
        "        # 0-pad the resized image. 0-pad to all left, right, top and bottom.\n",
        "        pad_size = self.size - resize\n",
        "        padded_img = _F.pad(resized_img, pad_size, fill=0)\n",
        "        # Crop the padded image to get (size, size) image.\n",
        "        pos_top = random.randint(0, pad_size)\n",
        "        pos_left = random.randint(0, pad_size)\n",
        "        transformed_img = _F.crop(padded_img, pos_top, pos_left, self.size, self.size)\n",
        "        return transformed_img\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaBmA8-tbqLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions.multinomial import Multinomial\n",
        "\n",
        "\n",
        "class SimpleModel(nn.Module):\n",
        "    \"\"\"SimpleModel represents a lightweight model for checking codes.\n",
        "\n",
        "    This model is quite simple to check codes quickly.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    self.num_classes int : number of classes of dataset.\n",
        "    self.layers nn.ModuleDict : ModuleDict of models.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        num_classes int : number of classes of dataset.\n",
        "        \"\"\"\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.Conv2d(3, 9, 3, padding=1, stride=1),\n",
        "            nn.GroupNorm(3, 9),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(9, self.num_classes, 1, padding=0, stride=2),\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        x torch.Tensor : input tensor whose shape is [b, c, h, w].\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.squeeze(x) torch.Tensor : logit tensor which will be input of softmax.\n",
        "        \"\"\"\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return torch.squeeze(x)\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    \"\"\"Model represents a model mainly used in experiments.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    self.num_classes int : number of classes of dataset.\n",
        "    self.layers nn.ModuleDict : ModuleDict of models.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        num_classes int : number of classes of dataset.\n",
        "        \"\"\"\n",
        "        super(Model, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.layers = nn.ModuleDict(OrderedDict([\n",
        "            # CONV-GN-ELU\n",
        "            (\"conv1\", nn.Conv2d(3, 96, 3, padding=1, stride=1)),\n",
        "            (\"GN1\", nn.GroupNorm(3, 96)),\n",
        "            (\"ELU1\", nn.ELU()),\n",
        "            # CONV-GN-ELU * 2 + Dropout\n",
        "            (\"conv2\", nn.Conv2d(96, 96, 3, padding=1, stride=1)),\n",
        "            (\"GN2\", nn.GroupNorm(3, 96)),\n",
        "            (\"ELU2\", nn.ELU()),\n",
        "            (\"conv3\", nn.Conv2d(96, 96, 3, padding=1, stride=2)),\n",
        "            (\"GN3\", nn.GroupNorm(3, 96)),\n",
        "            (\"ELU3\", nn.ELU()),\n",
        "            (\"DO1\", nn.Dropout(0.5)),\n",
        "            # CONV-GN-ELU * 3 + Dropout\n",
        "            (\"conv4\", nn.Conv2d(96, 192, 3, padding=1, stride=1)),\n",
        "            (\"GN4\", nn.GroupNorm(6, 192)),\n",
        "            (\"ELU4\", nn.ELU()),\n",
        "            (\"conv5\", nn.Conv2d(192, 192, 3, padding=1, stride=1)),\n",
        "            (\"GN5\", nn.GroupNorm(6, 192)),\n",
        "            (\"ELU5\", nn.ELU()),\n",
        "            (\"conv6\", nn.Conv2d(192, 192, 3, padding=1, stride=2)),\n",
        "            (\"GN6\", nn.GroupNorm(6, 192)),\n",
        "            (\"ELU6\", nn.ELU()),\n",
        "            (\"DO2\", nn.Dropout(0.5)),\n",
        "            # CONV-GN-ELU * 2 + CONV + GAP\n",
        "            (\"conv7\", nn.Conv2d(192, 192, 3, padding=1, stride=1)),\n",
        "            (\"GN7\", nn.GroupNorm(6, 192)),\n",
        "            (\"ELU7\", nn.ELU()),\n",
        "            (\"conv8\", nn.Conv2d(192, 192, 1, padding=0, stride=1)),\n",
        "            (\"GN8\", nn.GroupNorm(6, 192)),\n",
        "            (\"ELU8\", nn.ELU()),\n",
        "            (\"conv9\", nn.Conv2d(192, self.num_classes, 1, padding=0, stride=2)),\n",
        "            (\"pool\", nn.AdaptiveAvgPool2d(1))\n",
        "        ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        x torch.Tensor : input tensor whose shape is [b, c, h, w].\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.squeeze(x) torch.Tensor : logit tensor which will be input of softmax.\n",
        "        \"\"\"\n",
        "        for layer in self.layers.values():\n",
        "            x = layer(x)\n",
        "        return torch.squeeze(x)\n",
        "\n",
        "\n",
        "class StochasticActivationPruning(nn.Module):\n",
        "    \"\"\"SimpleModel represents a nn.Module of Stochastic Activation Pruning.\n",
        "\n",
        "    The original paper is https://arxiv.org/abs/1803.01442.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    self.ratio float : ratio of pruning which can be larger than 1.0.\n",
        "    self.is_valid bool : if this flag is True, inject SAP.\n",
        "    \"\"\"\n",
        "    def __init__(self, ratio=1.0, is_valid=False):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        ratio float : ratio of pruning which can be larger than 1.0.\n",
        "        is_valid bool : if this flag is True, inject SAP.\n",
        "        \"\"\"\n",
        "        super(StochasticActivationPruning, self).__init__()\n",
        "        self.ratio = ratio\n",
        "        self.is_valid = is_valid\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "\n",
        "        If self.training or not self.is_valid, just return inputs.\n",
        "        If self.is_valid apply SAP to inputs and return the result tensor.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs torch.Tensor : input tensor whose shape is [b, c, h, w].\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        outputs torch.Tensor : just return inputs or stochastically pruned inputs.\n",
        "        \"\"\"\n",
        "        if self.training or not self.is_valid:\n",
        "            return inputs\n",
        "        else:\n",
        "            b, c, h, w = inputs.shape\n",
        "            inputs_1d = inputs.reshape([b, c * h * w])  # [b, c * h * w]\n",
        "            outputs = torch.zeros_like(inputs_1d)  # outputs with 0 initilization\n",
        "            inputs_1d_sum = torch.sum(torch.abs(inputs_1d), dim=-1, keepdim=True)\n",
        "            inputs_1d_prob = torch.abs(inputs_1d) / inputs_1d_sum\n",
        "\n",
        "            repeat_num = int(c * h * w * self.ratio)\n",
        "            idx = Multinomial(repeat_num, inputs_1d_prob).sample()\n",
        "            outputs[idx.nonzero(as_tuple=True)] = inputs_1d[idx.nonzero(as_tuple=True)]\n",
        "            outputs = outputs / (1 - (1 - inputs_1d_prob) ** repeat_num + 1e-12)\n",
        "            outputs = outputs.reshape([b, c, h, w])  # [b, c, h, w]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class ModelSAP(nn.Module):\n",
        "    \"\"\"Model represents a model mainly used in experiments.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    self.num_classes int : number of classes of dataset.\n",
        "    self.layers nn.ModuleDict : ModuleDict of models.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        num_classes int : number of classes of dataset.\n",
        "        \"\"\"\n",
        "        super(ModelSAP, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.layers = nn.ModuleDict(OrderedDict([\n",
        "            # CONV-GN-ELU\n",
        "            (\"conv1\", nn.Conv2d(3, 96, 3, padding=1, stride=1)),\n",
        "            (\"GN1\", nn.GroupNorm(3, 96)),\n",
        "            (\"ELU1\", nn.ELU()),\n",
        "            (\"SAP1\", StochasticActivationPruning()),\n",
        "            # CONV-GN-ELU * 2 + Dropout\n",
        "            (\"conv2\", nn.Conv2d(96, 96, 3, padding=1, stride=1)),\n",
        "            (\"GN2\", nn.GroupNorm(3, 96)),\n",
        "            (\"ELU2\", nn.ELU()),\n",
        "            (\"SAP2\", StochasticActivationPruning()),\n",
        "            (\"conv3\", nn.Conv2d(96, 96, 3, padding=1, stride=2)),\n",
        "            (\"GN3\", nn.GroupNorm(3, 96)),\n",
        "            (\"ELU3\", nn.ELU()),\n",
        "            (\"SAP3\", StochasticActivationPruning()),\n",
        "            (\"DO1\", nn.Dropout(0.5)),\n",
        "            # CONV-GN-ELU * 3 + Dropout\n",
        "            (\"conv4\", nn.Conv2d(96, 192, 3, padding=1, stride=1)),\n",
        "            (\"GN4\", nn.GroupNorm(6, 192)),\n",
        "            (\"ELU4\", nn.ELU()),\n",
        "            (\"SAP4\", StochasticActivationPruning()),\n",
        "            (\"conv5\", nn.Conv2d(192, 192, 3, padding=1, stride=1)),\n",
        "            (\"GN5\", nn.GroupNorm(6, 192)),\n",
        "            (\"ELU5\", nn.ELU()),\n",
        "            (\"SAP5\", StochasticActivationPruning()),\n",
        "            (\"conv6\", nn.Conv2d(192, 192, 3, padding=1, stride=2)),\n",
        "            (\"GN6\", nn.GroupNorm(6, 192)),\n",
        "            (\"ELU6\", nn.ELU()),\n",
        "            (\"SAP6\", StochasticActivationPruning()),\n",
        "            (\"DO2\", nn.Dropout(0.5)),\n",
        "            # CONV-GN-ELU * 2 + CONV + GAP\n",
        "            (\"conv7\", nn.Conv2d(192, 192, 3, padding=1, stride=1)),\n",
        "            (\"GN7\", nn.GroupNorm(6, 192)),\n",
        "            (\"ELU7\", nn.ELU()),\n",
        "            (\"SAP7\", StochasticActivationPruning(is_valid=True)),\n",
        "            (\"conv8\", nn.Conv2d(192, 192, 1, padding=0, stride=1)),\n",
        "            (\"GN8\", nn.GroupNorm(6, 192)),\n",
        "            (\"ELU8\", nn.ELU()),\n",
        "            (\"SAP8\", StochasticActivationPruning(is_valid=True)),\n",
        "            (\"conv9\", nn.Conv2d(192, self.num_classes, 1, padding=0, stride=2)),\n",
        "            (\"pool\", nn.AdaptiveAvgPool2d(1))\n",
        "        ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        x torch.Tensor : input tensor whose shape is [b, c, h, w].\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.squeeze(x) torch.Tensor : logit tensor which will be input of softmax.\n",
        "        \"\"\"\n",
        "        for layer in self.layers.values():\n",
        "            x = layer(x)\n",
        "        return torch.squeeze(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPxrLNgscGlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AdvParams():\n",
        "    \"\"\"AdvParams represents parameters of adversarial attacks/defences.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    self.sampler torch.distribution : noise sampler for rfgsm (fixed as Normal[-1,1]).\n",
        "    self.epsilon float : scale of adversary [x - epsilon, x + epsilon].\n",
        "    self.alpha float : scale of noisze [x - alpha, x + alpha].\n",
        "    self.step int : iteration numbers for ifgsm/mifgsm.\n",
        "    self.train_method str : specify train adversarial method such \"fgsm\".\n",
        "    self.test_method str : specify test adversarial method such \"fgsm\".\n",
        "    self.is_train bool : indicate training/test.\n",
        "    \"\"\"\n",
        "    def __init__(self, epsilon, alpha, step, train_method, test_method, is_train=True):\n",
        "        self.sampler = torch.distributions.Normal(-1.0, 1.0)\n",
        "        self.epsilon = epsilon\n",
        "        self.alpha = alpha\n",
        "        self.step = step\n",
        "        self.train_method = train_method\n",
        "        self.test_method = test_method\n",
        "        self.is_train = is_train\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A8yEBbG4o_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, trainloader, save_path, epoch):\n",
        "    \"\"\"Train and save a model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model Model(nn.Module) : PyTorch model such as Model.\n",
        "    trainloader torch.utils.data.DataLoader : train data loader.\n",
        "    save_path str : model save path.\n",
        "    epoch int : epochs for model training.\n",
        "    \"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    for epoch in range(1, epoch + 1):\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 1):\n",
        "            x, y = data\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            logit = model(x)\n",
        "            loss = criterion(logit, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 200 == 0:\n",
        "                logging.info(f\"[{epoch}, {i:>5}] loss: {running_loss / 200:.3f}\")\n",
        "                running_loss = 0.0\n",
        "\n",
        "    logging.info('Finished Training.')\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "\n",
        "\n",
        "def _load_model_weight(model, model_path):\n",
        "    \"\"\"Load trained weights into a model.\n",
        "\n",
        "    Model case - just load trained weights.\n",
        "    ModelSAP case - skip SAP layers to load trained weights appropriately.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model Model(nn.Module) : PyTorch model such as Model.\n",
        "    model_path str : path to model trained in advance.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    model Model(nn.Module) : PyTorch model with loaded weights.\n",
        "    \"\"\"\n",
        "    if type(model) == SimpleModel or type(model) == Model:\n",
        "        model.load_state_dict(torch.load(model_path, map_location=torch.device(device)))\n",
        "    elif type(model) == ModelSAP:\n",
        "        pretrained_model = Model(model.num_classes).to(device)\n",
        "        pretrained_model.load_state_dict(torch.load(model_path,\n",
        "                                         map_location=torch.device(device)))\n",
        "        pretrained_dict = pretrained_model.state_dict()\n",
        "        model_dict = model.state_dict()\n",
        "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "        model_dict.update(pretrained_dict)\n",
        "        model.load_state_dict(pretrained_dict)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def test(model, testloader, model_path):\n",
        "    \"\"\"Test a trained model.\n",
        "\n",
        "    Results will be written in a log file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model Model(nn.Module) : PyTorch model such as Model.\n",
        "    testloader torch.utils.data.DataLoader : test data loader.\n",
        "    model_path str : path to a traiend model.\n",
        "    \"\"\"\n",
        "    model = _load_model_weight(model, model_path)\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    for x, y in testloader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        output = model(x)\n",
        "        final_pred = output.max(1, keepdim=True)[1]  # [1] : indices.\n",
        "        correct += int(sum(final_pred.flatten() == y))\n",
        "\n",
        "    final_acc = correct / float(testloader.__len__() * testloader.batch_size)\n",
        "    logging.info(f\"Accuracy on test data: {final_acc}\")\n",
        "\n",
        "\n",
        "def _gen_grad(x, y, logit, model, is_train):\n",
        "    \"\"\"Generate loss gradients of data.\n",
        "\n",
        "    If is_train is True, use model predictions as labels of loss function\n",
        "    to avoid label leaking (https://arxiv.org/abs/1611.01236).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x torch.Tensor : input data whose shape is [b, c, h, w].\n",
        "    y torch.Tensor : true label whose shape is [b].\n",
        "    logit torch.Tensor : logit tensor whose shape is [b, num_classes].\n",
        "    model Model(nn.Module) : Pytorch model.\n",
        "    is_train bool : Flag to denote training or not.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    data_grad torch.Tensor : loss gradients of data whose shape is [b, c, h, w].\n",
        "    \"\"\"\n",
        "    x.retain_grad()\n",
        "    if is_train:\n",
        "        y_model = logit.max(1, keepdim=False)[1].long().to(device)  # [1] : indices.\n",
        "        loss = F.nll_loss(F.log_softmax(logit, dim=1), y_model)\n",
        "    else:\n",
        "        loss = F.nll_loss(F.log_softmax(logit, dim=1), y)\n",
        "    model.zero_grad()\n",
        "    loss.backward(retain_graph=True)\n",
        "    data_grad = x.grad.data\n",
        "\n",
        "    return data_grad\n",
        "\n",
        "\n",
        "def fgsm_attack(x, y, logit, model, adv_params):\n",
        "    \"\"\"Generate loss gradients of data.\n",
        "\n",
        "    If is_train is True, use model predictions as labels of loss function\n",
        "    to avoid label leaking (https://arxiv.org/abs/1611.01236).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x torch.Tensor : input data whose shape is [b, c, h, w].\n",
        "    y torch.Tensor : true label whose shape is [b].\n",
        "    logit torch.Tensor : logit tensor whose shape is [b, num_classes].\n",
        "    model Model(nn.Module) : PyTorch model.\n",
        "    adv_params AdvParams : parameters of adversary.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    x_adv torch.Tensor : perturbated x whose shape is [b, c, h, w].\n",
        "    \"\"\"\n",
        "    data_grad = _gen_grad(x, y, logit, model, adv_params.is_train)\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    x_adv = x + adv_params.epsilon * sign_data_grad\n",
        "    x_adv = torch.clamp(x_adv, 0, 1)\n",
        "\n",
        "    return x_adv\n",
        "\n",
        "\n",
        "def rfgsm_attack(x, y, logit, model, adv_params):\n",
        "    \"\"\"Generate loss gradients of data.\n",
        "\n",
        "    Randomized FGSM: https://arxiv.org/abs/1705.07204.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x torch.Tensor : input data whose shape is [b, c, h, w].\n",
        "    y torch.Tensor : true label whose shape is [b].\n",
        "    logit torch.Tensor : logit tensor whose shape is [b, num_classes].\n",
        "    model Model(nn.Module) : PyTorch model.\n",
        "    adv_params AdvParams : parameters of adversary.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    x_adv torch.Tensor : perturbated x whose shape is [b, c, h, w].\n",
        "    \"\"\"\n",
        "    sign_noise = adv_params.sampler.sample(x.shape).to(device).sign()\n",
        "    x_noise = x + adv_params.alpha * sign_noise\n",
        "    x_noise = torch.clamp(x_noise, 0, 1)\n",
        "    logit_noise = model(x_noise)\n",
        "    adv_params.epsilon = adv_params.epsilon - adv_params.alpha\n",
        "    x_adv = fgsm_attack(x_noise, y, logit_noise, model, adv_params)\n",
        "    adv_params.epsilon = adv_params.epsilon + adv_params.alpha\n",
        "\n",
        "    return x_adv\n",
        "\n",
        "\n",
        "def ifgsm_attack(x, y, model, adv_params):\n",
        "    \"\"\"Generate loss gradients of data.\n",
        "\n",
        "    Projected Gradient Descent : https://arxiv.org/abs/1706.06083.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x torch.Tensor : input data whose shape is [b, c, h, w].\n",
        "    y torch.Tensor : true label whose shape is [b].\n",
        "    model Model(nn.Module) : PyTorch model.\n",
        "    adv_params AdvParams : parameters of adversary.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    x_adv torch.Tensor : perturbated x whose shape is [b, c, h, w].\n",
        "    \"\"\"\n",
        "    x_adv = x\n",
        "\n",
        "    epsilon_org = adv_params.epsilon\n",
        "    adv_params.epsilon = epsilon_org / 10.0\n",
        "    for _ in range(adv_params.step):\n",
        "        logit = model(x_adv)\n",
        "        x_adv = fgsm_attack(x_adv, y, logit, model, adv_params)\n",
        "        # Clip x_adv within [x - eps, x + eps]\n",
        "        x_adv = torch.max(torch.min(x_adv, x + epsilon_org), x - epsilon_org)\n",
        "        x_adv = torch.clamp(x_adv, 0, 1)\n",
        "\n",
        "    adv_params.epsilon = epsilon_org\n",
        "    return x_adv\n",
        "\n",
        "\n",
        "def mifgsm_attack(x, y, model, adv_params):\n",
        "    \"\"\"Generate loss gradients of data.\n",
        "\n",
        "    Momentum Iterative FGSM: https://arxiv.org/abs/1710.06081.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x torch.Tensor : input data whose shape is [b, c, h, w].\n",
        "    y torch.Tensor : true label whose shape is [b].\n",
        "    model Model(nn.Module) : PyTorch model.\n",
        "    adv_params AdvParams : parameters of adversary.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    x_adv torch.Tensor : perturbated x whose shape is [b, c, h, w].\n",
        "    \"\"\"\n",
        "    decay_factor = 1.0\n",
        "    scale = adv_params.epsilon / 5.0\n",
        "\n",
        "    momentum = torch.zeros_like(x)\n",
        "    x_adv = x\n",
        "\n",
        "    for _ in range(adv_params.step):\n",
        "        outputs = model(x_adv)\n",
        "        data_grad = _gen_grad(x_adv, y, outputs, model, adv_params.is_train)\n",
        "        reduce_idx = list(range(1, len(data_grad.shape)))\n",
        "        denominator = torch.mean(torch.abs(data_grad), reduce_idx, keepdim=True)\n",
        "        data_grad = data_grad / torch.max(denominator, denominator + 1e-12)\n",
        "        momentum = decay_factor * momentum + data_grad\n",
        "\n",
        "        sign_momentum = data_grad.sign()\n",
        "        scaled_grad = scale * sign_momentum\n",
        "        x_adv = x_adv + scaled_grad\n",
        "        # Clip x_adv within [x - eps, x + eps]\n",
        "        x_adv = torch.max(torch.min(x_adv, x + adv_params.epsilon),\n",
        "                          x - adv_params.epsilon)\n",
        "        x_adv = torch.clamp(x_adv, 0, 1)\n",
        "\n",
        "    return x_adv\n",
        "\n",
        "\n",
        "def create_adv_sample(x, y, logit, model, adv_params, adv_method):\n",
        "    \"\"\"Create adversarial examples using adv_method.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x torch.Tensor : input data whose shape is [b, c, h, w].\n",
        "    y torch.Tensor : true label whose shape is [b].\n",
        "    logit torch.Tensor : logit tensor whose shape is [b, num_classes].\n",
        "    model Model(nn.Module) : PyTorch model.\n",
        "    adv_params AdvParams : parameters of adversary.\n",
        "    adv_method str : adversary method used to create x_adv.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    x_adv torch.Tensor : perturbated x whose shape is [b, c, h, w].\n",
        "    \"\"\"\n",
        "    if adv_method == \"fgsm\":\n",
        "        x_adv = fgsm_attack(x, y, logit, model, adv_params)\n",
        "    elif adv_method == \"rfgsm\":\n",
        "        x_adv = rfgsm_attack(x, y, logit, model, adv_params)\n",
        "    elif adv_method == \"ifgsm\":\n",
        "        x_adv = ifgsm_attack(x, y, model, adv_params)\n",
        "    elif adv_method == \"mifgsm\":\n",
        "        x_adv = mifgsm_attack(x, y, model, adv_params)\n",
        "\n",
        "    return x_adv\n",
        "\n",
        "\n",
        "def train_adv(model, trainloader, save_path, epoch, adv_params):\n",
        "    \"\"\"Train a model using adversarial training and save the trained model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model Model(nn.Module) : PyTorch model such as Model.\n",
        "    trainloader torch.utils.data.DataLoader : train DataLoader\n",
        "    save_path str : model save path.\n",
        "    epoch int : epochs for model training.\n",
        "    adv_params AdvParams : parameters of adversary.\n",
        "    \"\"\"\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    for epoch in range(1, epoch + 1):\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 1):\n",
        "            x, y = data\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            x.requires_grad = True\n",
        "\n",
        "            logit = model(x)\n",
        "            x_adv = create_adv_sample(x, y, logit, model, adv_params,\n",
        "                                      adv_params.train_method)\n",
        "            logit_adv = model(x_adv)\n",
        "\n",
        "            # Adversarial training\n",
        "            optimizer.zero_grad()\n",
        "            adv_loss = (0.8 * F.cross_entropy(logit, y)\n",
        "                        + (1 - 0.8) * F.cross_entropy(logit_adv, y))\n",
        "            adv_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += adv_loss.item()\n",
        "            if i % 200 == 0:\n",
        "                logging.info(f\"[{epoch}, {i:>5}] loss: {running_loss / 200:.3f}\")\n",
        "                running_loss = 0.0\n",
        "\n",
        "    logging.info('Finished Training.')\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "\n",
        "\n",
        "def train_atda(model, trainloader, save_path, epoch, adv_params):\n",
        "    \"\"\"Train a model using adversarial training with domain adaptation.\n",
        "\n",
        "    This training method is based on https://arxiv.org/abs/1810.00740.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model Model(nn.Module) : PyTorch model such as Model.\n",
        "    trainloader torch.utils.data.DataLoader : train DataLoader\n",
        "    save_path str : model save path.\n",
        "    epoch int : epochs for model training.\n",
        "    adv_params AdvParams : parameters of adversary.\n",
        "    \"\"\"\n",
        "    def _coral_loss(source, target):\n",
        "        \"\"\"Compute CORAL loss between source and target.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        source torch.Tensor : tensor of source domain.\n",
        "        target torch.Tensor : tensor of target domain.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss torch.Tensor : loss tensor.\n",
        "        \"\"\"\n",
        "        mean_s = torch.mean(source, dim=0, keepdim=True) - source\n",
        "        covariance_s = torch.matmul(torch.transpose(mean_s, 0, 1), mean_s)\n",
        "        mean_t = torch.mean(target, dim=0, keepdim=True) - target\n",
        "        covariance_t = torch.matmul(torch.transpose(mean_t, 0, 1), mean_t)\n",
        "        loss = torch.mean(torch.abs(covariance_s - covariance_t))\n",
        "        return loss\n",
        "\n",
        "    def _mmd_loss(source, target):\n",
        "        \"\"\"Compute MMD loss between source and target.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        source torch.Tensor : tensor of source domain.\n",
        "        target torch.Tensor : tensor of target domain.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss torch.Tensor : loss tensor.\n",
        "        \"\"\"\n",
        "        mean_s = torch.mean(source, dim=0) - source\n",
        "        mean_t = torch.mean(target, dim=0) - target\n",
        "        loss = torch.mean(torch.abs(mean_s - mean_t))\n",
        "        return loss\n",
        "\n",
        "    def _margin_loss(logit, logit_adv, y, centers):\n",
        "        \"\"\"Compute margin loss between source and target.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        logit torch.Tensor : logit tensor of source domain.\n",
        "        logit torch.Tensor : logit tensor of target domain.\n",
        "        y torch.Tensor : label.\n",
        "        centers torch.Tensor : class centers in the logit space.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss torch.Tensor : loss tensor.\n",
        "        centers torch.Tensor : updated class centers.\n",
        "        \"\"\"\n",
        "        # Parameter\n",
        "        alpha = 0.1\n",
        "\n",
        "        concat_logit = torch.cat((logit, logit_adv), dim=0)  # [2 * b, len(logit)]\n",
        "        concat_y = torch.cat((y, y), dim=0)  # [2 * b]\n",
        "        centers_batch = centers[concat_y, :]  # [2 * b, len(logit)]\n",
        "        centers_dist = torch.mean(\n",
        "            torch.abs(concat_logit - centers_batch), dim=1)  # [2 * b]\n",
        "\n",
        "        diff_batch = centers_batch - concat_logit\n",
        "        unique_num, unique_idx, unique_count = torch.unique(concat_y,\n",
        "                                                            return_inverse=True,\n",
        "                                                            return_counts=True)\n",
        "        appearance_num = unique_count[unique_idx].unsqueeze(1).float()  # [2 * b, 1]\n",
        "        diff_batch = alpha * (diff_batch / (1. + appearance_num))\n",
        "        diff = torch.zeros_like(centers).index_add_(\n",
        "            0, concat_y, diff_batch)  # [num_classes, len(logit)]\n",
        "\n",
        "        # Update center positions.\n",
        "        centers = centers - diff.data\n",
        "\n",
        "        logit_center_pair_dist = torch.sum(\n",
        "            torch.abs(concat_logit.unsqueeze(1) - centers.unsqueeze(0)),\n",
        "            # [2 * b, num_classes, len(logit)]\n",
        "            dim=2)  # [2 * b, num_classes]\n",
        "        logit_center_dist = centers_dist.unsqueeze(1) - logit_center_pair_dist\n",
        "        # logit_center_dist: [2 * b, num_classes]\n",
        "        logit_center_labels_equal = (concat_y.unsqueeze(1) == torch.Tensor(\n",
        "            [c for c in range(centers.shape[0])]).to(device).unsqueeze(0))\n",
        "        # logit_center_labels_equal: [2 * b, num_classes]\n",
        "        mask = torch.logical_not(logit_center_labels_equal)\n",
        "\n",
        "        loss = torch.sum(F.softplus(logit_center_dist) * mask) / torch.sum(mask)\n",
        "\n",
        "        return loss, centers\n",
        "\n",
        "    centers = torch.zeros([model.num_classes, model.num_classes],\n",
        "                          dtype=torch.float32, requires_grad=False).to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    for epoch in range(1, epoch + 1):\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 1):\n",
        "            x, y = data\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            x.requires_grad = True\n",
        "\n",
        "            logit = model(x)\n",
        "            x_adv = create_adv_sample(x, y, logit, model, adv_params,\n",
        "                                      adv_params.train_method)\n",
        "            logit_adv = model(x_adv)\n",
        "\n",
        "            # Adversarial training with domain adaptation\n",
        "            optimizer.zero_grad()\n",
        "            coral_loss = _coral_loss(logit, logit_adv)\n",
        "            mmd_loss = _mmd_loss(logit, logit_adv)\n",
        "            margin_loss, centers = _margin_loss(logit, logit_adv, y, centers)\n",
        "            adv_loss = (F.cross_entropy(logit, y)\n",
        "                        + F.cross_entropy(logit_adv, y)\n",
        "                        + 1 / 3. * (coral_loss + mmd_loss + margin_loss))\n",
        "            adv_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Logging\n",
        "            running_loss += adv_loss.item()\n",
        "            if i % 200 == 0:\n",
        "                logging.info(f\"[{epoch}, {i:>5}] loss: {running_loss / 200:.3f}\")\n",
        "                running_loss = 0.0\n",
        "\n",
        "    logging.info('Finished Training.')\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "\n",
        "\n",
        "def test_adv(model, testloader, model_path, adv_params, adv_img_save_base):\n",
        "    \"\"\"Test a trained mode with adversarial test data.\n",
        "\n",
        "    Results will be written in a log file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model Model(nn.Module) : PyTorch model such as Model.\n",
        "    testloader torch.utils.data.DataLoader : test data loader.\n",
        "    model_path str : path to a traiend model.\n",
        "    adv_params AdvParams : parameters of adversary.\n",
        "    adv_img_save_base str : base path to save adversarial examples.\n",
        "    \"\"\"\n",
        "    # Parameter\n",
        "    save_adv_img_num = 5\n",
        "\n",
        "    model = _load_model_weight(model, model_path)\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    misclassified_adv_examples = []\n",
        "\n",
        "    for x, y in testloader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x.requires_grad = True\n",
        "\n",
        "        logit = model(x)\n",
        "        init_pred = logit.max(1, keepdim=True)[1].flatten()  # [1] : indices.\n",
        "        x_adv = create_adv_sample(x, y, logit, model, adv_params,\n",
        "                                  adv_params.test_method)\n",
        "        logit_adv = model(x_adv)\n",
        "\n",
        "        final_pred = logit_adv.max(1, keepdim=True)[1].flatten()  # [1] : indices.\n",
        "        for x_i, x_adv_i, y_i, ip_i, fp_i in zip(x, x_adv, y, init_pred, final_pred):\n",
        "            if fp_i == y_i:\n",
        "                correct += 1\n",
        "            elif ip_i == y_i and len(misclassified_adv_examples) < save_adv_img_num:\n",
        "                misclassified_adv_examples.append((x_i, x_adv_i))\n",
        "\n",
        "    final_acc = correct / float(testloader.__len__() * testloader.batch_size)\n",
        "    logging.info(f\"Accuracy on test_adv data: {final_acc}\")\n",
        "\n",
        "    # Save adversarial examples\n",
        "    for idx, (x_i, x_adv_i) in enumerate(misclassified_adv_examples, start=1):\n",
        "        x_i_np = x_i.transpose(0, 1).transpose(1, 2).detach().cpu().numpy()\n",
        "        x_adv_i_np = x_adv_i.transpose(0, 1).transpose(1, 2).detach().cpu().numpy()\n",
        "        im = Image.fromarray((x_i_np * 255).astype(np.uint8))\n",
        "        im_adv = Image.fromarray((x_adv_i_np * 255).astype(np.uint8))\n",
        "        im_merged = Image.new('RGB', (2 * im.width, im.height))\n",
        "        im_merged.paste(im, (0, 0))\n",
        "        im_merged.paste(im_adv, (im.width, 0))\n",
        "        im_merged.save(f\"{adv_img_save_base}{idx}.png\")\n",
        "\n",
        "\n",
        "def exp_kde(model, trainloader, testloader, model_path, adv_params):\n",
        "    \"\"\"Test a trained mode with adversarial test data.\n",
        "\n",
        "    Results will be written in a log file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model Model(nn.Module) : PyTorch model such as Model.\n",
        "    trainloader torch.utils.data.DataLoader : train data loader.\n",
        "    testloader torch.utils.data.DataLoader : test data loader.\n",
        "    model_path str : path to a traiend model.\n",
        "    adv_params AdvParams : parameters of adversary.\n",
        "    \"\"\"\n",
        "    def _compute_logits(loader, num_classes, adv_method):\n",
        "        \"\"\"Compute logits and prediction labels of model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        loader torch.utils.data.DataLoader : data loader of train/test.\n",
        "        num_classes int : number of classes.\n",
        "        adv_method str : adversary method to compute logit.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        logits torch.Tensor : logits obtained from model.\n",
        "        labels torch.Tensor : labels.\n",
        "        labels_pred torch.Tensor : model prediction labels.\n",
        "        \"\"\"\n",
        "        logits = np.zeros(shape=(len(loader.dataset), num_classes))\n",
        "        labels = np.zeros(shape=(len(loader.dataset)))\n",
        "        labels_pred = np.zeros(shape=(len(loader.dataset)))\n",
        "        for idx, (x, y) in enumerate(loader):\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            x.requires_grad = True\n",
        "\n",
        "            logit = model(x)\n",
        "\n",
        "            if adv_method == \"none\":\n",
        "                pass\n",
        "            else:\n",
        "                x_adv = create_adv_sample(x, y, logit, model, adv_params, adv_method)\n",
        "                # Overwrite logit.\n",
        "                logit = model(x_adv)\n",
        "\n",
        "            pred = logit.max(1, keepdim=True)[1].flatten()  # [1] : indices.\n",
        "            start = idx * loader.batch_size\n",
        "            end = (idx + 1) * loader.batch_size\n",
        "            logits[start : end, :] = logit.cpu().detach().numpy()\n",
        "            labels[start : end] = y.cpu().detach().numpy().astype(np.int)\n",
        "            labels_pred[start : end] = pred.cpu().detach().numpy().astype(np.int)\n",
        "\n",
        "        return logits, labels, labels_pred\n",
        "\n",
        "    def _compute_kde_score(label, feature):\n",
        "        \"\"\"Compute Kernel Density Estimation of feature by kdes[label].\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        label torch.Tensor (single data) : label.\n",
        "        feature torch.Tensor (single data) : feature.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float : computed kde score.\n",
        "        \"\"\"\n",
        "        return float(kdes[label].score_samples(np.reshape(feature, (1, -1))).squeeze())\n",
        "\n",
        "    def _compute_densities(labels, features):\n",
        "        \"\"\"Compute KDE densities.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        labels torch.Tensor : labels.\n",
        "        features torch.Tensor : features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        densities List[float] : all densities.\n",
        "        \"\"\"\n",
        "        densities = []\n",
        "        for label, feature in zip(labels, features):\n",
        "            densities.append(_compute_kde_score(label, feature))\n",
        "\n",
        "        return densities\n",
        "\n",
        "    model = _load_model_weight(model, model_path)\n",
        "    model.eval()\n",
        "\n",
        "    logging.info(f\"Train KDEs for each class.\")\n",
        "\n",
        "    logits_train, labels_train, _ = _compute_logits(trainloader, model.num_classes,\n",
        "                                                    \"none\")\n",
        "\n",
        "    kdes = {}\n",
        "    for class_idx in range(model.num_classes):\n",
        "        kdes[class_idx] = KernelDensity(kernel='gaussian', bandwidth=2.25).fit(\n",
        "            logits_train[np.where(labels_train == class_idx)])\n",
        "\n",
        "    logging.info(f\"Finished the training.\")\n",
        "\n",
        "    logging.info(f\"Compute densities for both clean and adv. test data.\")\n",
        "\n",
        "    # Clean test data.\n",
        "    logits_test, labels_test, labels_pred_test = _compute_logits(testloader,\n",
        "                                                                 model.num_classes,\n",
        "                                                                 \"none\")\n",
        "    densities = _compute_densities(labels_pred_test, logits_test)\n",
        "\n",
        "    # Adversarial test data.\n",
        "    logits_test_adv, _, labels_pred_adv = _compute_logits(testloader, model.num_classes,\n",
        "                                                          adv_params.test_method)\n",
        "    densities_adv = _compute_densities(labels_pred_adv, logits_test_adv)\n",
        "\n",
        "    logging.info(f\"Finished computing the densities.\")\n",
        "\n",
        "    logging.info(f\"Evaluate the computed densities\")\n",
        "\n",
        "    # d is log(prob), so p(x_adv) / p(x) < 1 is d(x) / d(x_adv) < 1\n",
        "    ratios = [d / d_adv for (d, d_adv) in zip(densities, densities_adv)]\n",
        "    ratios_smaller_than_one = sum(map(lambda x: x < 1, ratios)) / len(ratios)\n",
        "    logging.info(f\"Result (p(x_adv) / p(x) < 1): {ratios_smaller_than_one}.\")\n",
        "\n",
        "    features = np.reshape(np.concatenate([densities, densities_adv]), (-1, 1))\n",
        "    labels = np.concatenate([np.zeros_like(densities), np.ones_like(densities_adv)])\n",
        "    lr = LogisticRegressionCV(n_jobs=-1, random_state=23).fit(features, labels)\n",
        "    accuracy = sum(lr.predict(features) == labels) / len(labels)\n",
        "    logging.info(f\"Result (ACC): {accuracy}.\")\n",
        "\n",
        "    probs = lr.predict_proba(features)[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(labels, probs)\n",
        "    auc_score = auc(fpr, tpr)\n",
        "    logging.info(f\"Result (ROC-AUC): {auc_score}.\")\n",
        "\n",
        "    logging.info(f\"Finished evaluating the densities.\")\n",
        "\n",
        "\n",
        "def exp_random_crop(model, testloader, model_path, adv_params, size):\n",
        "    \"\"\"Test a trained model with random resize and crop.\n",
        "\n",
        "    Results will be written in a log file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model Model(nn.Module) : PyTorch model such as Model.\n",
        "    testloader torch.utils.data.DataLoader : test data loader.\n",
        "    model_path str : path to a traiend model.\n",
        "    adv_params AdvParams : parameters of adversary.\n",
        "    size int : original image will be scaled to this size.\n",
        "    \"\"\"\n",
        "    def _random_resize_crop(img, size):\n",
        "        img = img.unsqueeze(0)\n",
        "        # Randomly resize the image.\n",
        "        resize = random.randint(img.shape[-1], size - 1)\n",
        "        resized_img = F.interpolate(img, (resize, resize))\n",
        "        # 0-pad the resized image. 0-pad to all left, right, top and bottom.\n",
        "        pad_size = size - resize\n",
        "        padded_img = F.pad(resized_img, (pad_size,) * 4)\n",
        "        # Crop the padded image to get (size, size) image.\n",
        "        pos_top = random.randint(0, pad_size)\n",
        "        pos_left = random.randint(0, pad_size)\n",
        "        return padded_img[0, :, pos_top:pos_top + size, pos_left:pos_left + size]\n",
        "\n",
        "    model = _load_model_weight(model, model_path)\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    correct_adv = 0\n",
        "\n",
        "    for x, y in testloader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x.requires_grad = True\n",
        "\n",
        "        batches, channels, _, _ = x.shape\n",
        "        transformed_x = torch.zeros([batches, channels, size, size]).to(device)\n",
        "        for b in range(batches):\n",
        "            transformed_img = _random_resize_crop(x[b, :, :, :], size)\n",
        "            transformed_x[b, :, :, :] = transformed_img\n",
        "        logit = model(transformed_x)\n",
        "        pred = logit.max(1, keepdim=True)[1].flatten()  # [1] : indices.\n",
        "\n",
        "        x_adv = create_adv_sample(x, y, logit, model, adv_params,\n",
        "                                  adv_params.test_method)\n",
        "        transformed_x_adv = torch.zeros([batches, channels, size, size]).to(device)\n",
        "        for b in range(batches):\n",
        "            transformed_img_adv = _random_resize_crop(x_adv[b, :, :, :], size)\n",
        "            transformed_x_adv[b, :, :, :] = transformed_img_adv\n",
        "        logit_adv = model(transformed_x_adv)\n",
        "        pred_adv = logit_adv.max(1, keepdim=True)[1].flatten()  # [1] : indices.\n",
        "\n",
        "        for y_i, p_i, p_adv_i in zip(y, pred, pred_adv):\n",
        "            if y_i == p_i:\n",
        "                correct += 1\n",
        "            if y_i == p_adv_i:\n",
        "                correct_adv += 1\n",
        "\n",
        "    final_acc = correct / float(testloader.__len__() * testloader.batch_size)\n",
        "    final_acc_adv = correct_adv / float(testloader.__len__() * testloader.batch_size)\n",
        "    logging.info(f\"Accuracy on test data: {final_acc}\")\n",
        "    logging.info(f\"Accuracy on test_adv data: {final_acc_adv}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0kkwDUBpfMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(argv):\n",
        "    def _loggig_all_flags():\n",
        "        \"\"\"Logging information of all flags.\n",
        "        \"\"\"\n",
        "        for k, v in FLAGS.__flags.items():\n",
        "            logging.info(f\"{k} : {v.value}\")\n",
        "\n",
        "    def _generate_model_path(is_train=True, model_name=None):\n",
        "        \"\"\"Generate model path using FLAGS information.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        is_train bool : train or test.\n",
        "        model_name str : model name to be loaded in the test phase.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        model_path str : model path to save/load a model.\n",
        "        \"\"\"\n",
        "        model_dir = f\"./model/{FLAGS.dataset}\"\n",
        "        os.makedirs(model_dir, exist_ok=True)\n",
        "        model_path = f\"{model_dir}/\"\n",
        "\n",
        "        if is_train:\n",
        "            model_path += f\"model_{FLAGS.model}_{FLAGS.train_method}\"\n",
        "            if FLAGS.use_atda_loss:\n",
        "                model_path += \"_atda\"\n",
        "            model_path += \".pt\"\n",
        "        else:\n",
        "            model_path += model_name.split(\".pt\")[0]\n",
        "            model_path += \".pt\"\n",
        "\n",
        "        return model_path\n",
        "\n",
        "    # logging.set_verbosity(logging.INFO)\n",
        "    # if FLAGS.log_dir != '':\n",
        "    #     logging.get_absl_handler().use_absl_log_file()\n",
        "    # _loggig_all_flags()\n",
        "\n",
        "    if FLAGS.dataset == \"cifar10\":\n",
        "        Data = DataCIFAR10(batch_size=FLAGS.batch_size)\n",
        "    elif FLAGS.dataset == \"GTSRB_processed\":\n",
        "        Data = DataGTSRB(batch_size=FLAGS.batch_size)\n",
        "    trainloader, testloader, num_classes = Data.prepare_data()\n",
        "\n",
        "    model_path = _generate_model_path()\n",
        "\n",
        "    if FLAGS.model == \"simple\":\n",
        "        model = SimpleModel(num_classes).to(device)\n",
        "    elif FLAGS.model == \"normal\":\n",
        "        model = Model(num_classes).to(device)\n",
        "    elif FLAGS.model == \"normalSAP\":\n",
        "        model = ModelSAP(num_classes).to(device)\n",
        "\n",
        "    adv_params = AdvParams(FLAGS.epsilon, FLAGS.alpha, FLAGS.step,\n",
        "                           FLAGS.train_method, FLAGS.test_method)\n",
        "    if FLAGS.is_train:\n",
        "        if FLAGS.train_method == \"none\":\n",
        "            train(model, trainloader, model_path, FLAGS.epochs)\n",
        "        else:\n",
        "            adv_params.is_train = True\n",
        "            if FLAGS.use_atda_loss:\n",
        "                train_atda(model, trainloader, model_path, FLAGS.epochs, adv_params)\n",
        "            else:\n",
        "                train_adv(model, trainloader, model_path, FLAGS.epochs, adv_params)\n",
        "\n",
        "    if FLAGS.model_name_for_test is not None:\n",
        "        model_path = _generate_model_path(False, FLAGS.model_name_for_test)\n",
        "\n",
        "    if FLAGS.is_test:\n",
        "        if FLAGS.test_method == \"none\":\n",
        "            test(model, testloader, model_path)\n",
        "        else:\n",
        "            adv_params.is_train = False\n",
        "            adv_img_save_base = \"./data/adv_img_\"\n",
        "            adv_img_save_base += f\"{FLAGS.dataset}_{FLAGS.model}_\"\n",
        "            adv_img_save_base += f\"{FLAGS.train_method}_{FLAGS.test_method}_\"\n",
        "            test_adv(model, testloader, model_path, adv_params, adv_img_save_base)\n",
        "\n",
        "    if FLAGS.is_kde_test:\n",
        "        exp_kde(model, trainloader, testloader, model_path, adv_params)\n",
        "\n",
        "    if FLAGS.is_random_crop_test:\n",
        "        adv_params.is_train = False\n",
        "        if FLAGS.dataset == \"cifar10\":\n",
        "            exp_random_crop(model, testloader, model_path, adv_params, 34)\n",
        "        elif FLAGS.dataset == \"GTSRB_processed\":\n",
        "            exp_random_crop(model, testloader, model_path, adv_params, 55)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr5Bcw35pudg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "main(\"no argv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oydL3dnuOPKg",
        "colab_type": "text"
      },
      "source": [
        "Result example:\n",
        "\n",
        "CIFAR10-normal-train_method_none-test_method_fgsm.\n",
        "\n",
        "```\n",
        "Accuracy on test_adv data: 0.10343450479233227\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HX4mgn3ygU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsH9OieUOf1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOBm2Rj0ygkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}